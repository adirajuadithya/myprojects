{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b870cb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.9.0.1-cp39-cp39-win_amd64.whl (49.8 MB)\n",
      "     ---------------------------------------- 49.8/49.8 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "     -------------------------------------- 124.6/124.6 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from mediapipe) (1.21.5)\n",
      "Collecting protobuf<4,>=3.11\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "     -------------------------------------- 904.2/904.2 kB 9.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\anaconda\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\anaconda\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (from mediapipe) (3.5.2)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Installing collected packages: flatbuffers, protobuf, absl-py, mediapipe\n",
      "Successfully installed absl-py-1.3.0 flatbuffers-22.12.6 mediapipe-0.9.0.1 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fa86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "  \n",
    "# Configuration Face Mesh.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh =  mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "  \n",
    "img = cv2.imread('320654582_483194113959822_3066599250046978556_n.jpg', cv2.IMREAD_UNCHANGED)\n",
    "image = cv2.cvtColor(cv2.flip(img, 1), cv2.COLOR_BGR2RGB)\n",
    "# To improve performance.\n",
    "image.flags.writeable = False\n",
    "results =  face_mesh.process(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd42828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499.45507049560547, 198.82525420188904)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results.multi_face_landmarks[0].landmark[205].x * image.shape[1], results.multi_face_landmarks[0].landmark[205].y * image.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d1443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faceBlendCommon (from versions: none)\n",
      "ERROR: No matching distribution found for faceBlendCommon\n"
     ]
    }
   ],
   "source": [
    "!pip install faceBlendCommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2e45ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faceBlendCommon (from versions: none)\n",
      "ERROR: No matching distribution found for faceBlendCommon\n"
     ]
    }
   ],
   "source": [
    "!pip install faceBlendCommon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292e8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python faceBlendCommon.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f09d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import faceBlendCommon as fbc\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "803961c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement load_filter_img (from versions: none)\n",
      "ERROR: No matching distribution found for load_filter_img\n"
     ]
    }
   ],
   "source": [
    "!pip install load_filter_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "610c8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE_FACE_POINTS = False\n",
    " \n",
    "filters_config = {\n",
    "    'anonymous':\n",
    "        [{'path': \"filters/anonymous.png\",\n",
    "         'anno_path': \"filters/anonymous_annotations.csv\",\n",
    "         'morph': True, 'animated': False, 'has_alpha': True}],\n",
    "    'anime':\n",
    "        [{'path': \"filters/anime.png\",\n",
    "         'anno_path': \"filters/anime_annotations.csv\",\n",
    "         'morph': True, 'animated': False, 'has_alpha': True}],\n",
    "    'dog':\n",
    "        [{'path': \"filters/dog-ears.png\",\n",
    "         'anno_path': \"filters/dog-ears_annotations.csv\",\n",
    "         'morph': False, 'animated': False, 'has_alpha': True},\n",
    "         {'path': \"filters/dog-nose.png\",\n",
    "          'anno_path': \"filters/dog-nose_annotations.csv\",\n",
    "          'morph': False, 'animated': False, 'has_alpha': True}],\n",
    "    'cat':\n",
    "        [{'path': \"filters/cat-ears.png\",\n",
    "         'anno_path': \"filters/cat-ears_annotations.csv\",\n",
    "         'morph': False, 'animated': False, 'has_alpha': True},\n",
    "         {'path': \"filters/cat-nose.png\",\n",
    "          'anno_path': \"filters/cat-nose_annotations.csv\",\n",
    "          'morph': False, 'animated': False, 'has_alpha': True}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c393d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLandmarks(img):\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    selected_keypoint_indices = [127, 93, 58, 136, 150, 149, 176, 148, 152, 377, 400, 378, 379, 365, 288, 323, 356, 70, 63, 105, 66, 55,\n",
    "                 285, 296, 334, 293, 300, 168, 6, 195, 4, 64, 60, 94, 290, 439, 33, 160, 158, 173, 153, 144, 398, 385,\n",
    "                 387, 466, 373, 380, 61, 40, 39, 0, 269, 270, 291, 321, 405, 17, 181, 91, 78, 81, 13, 311, 306, 402, 14,\n",
    "                 178, 162, 54, 67, 10, 297, 284, 389]\n",
    " \n",
    "    height, width = img.shape[:-1]\n",
    " \n",
    "    with mp_face_mesh.FaceMesh(max_num_faces=1, static_image_mode=True, min_detection_confidence=0.5) as face_mesh:\n",
    " \n",
    "        results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    " \n",
    "        if not results.multi_face_landmarks:\n",
    "            print('Face not detected!!!')\n",
    "            return 0\n",
    " \n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            values = np.array(face_landmarks.landmark)\n",
    "            face_keypnts = np.zeros((len(values), 2))\n",
    " \n",
    "            for idx,value in enumerate(values):\n",
    "                face_keypnts[idx][0] = value.x\n",
    "                face_keypnts[idx][1] = value.y\n",
    " \n",
    "            # Convert normalized points to image coordinates\n",
    "            face_keypnts = face_keypnts * (width, height)\n",
    "            face_keypnts = face_keypnts.astype('int')\n",
    " \n",
    "            relevant_keypnts = []\n",
    " \n",
    "            for i in selected_keypoint_indices:\n",
    "                relevant_keypnts.append(face_keypnts[i])\n",
    "            return relevant_keypnts\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46d7173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter(img_path, has_alpha):\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    " \n",
    "    alpha = None\n",
    "    if has_alpha:\n",
    "        b, g, r, alpha = cv2.split(img)\n",
    "        img = cv2.merge((b, g, r))\n",
    " \n",
    "    return img, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa4d2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_landmarks(annotation_file):\n",
    "    with open(annotation_file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "        points = {}\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            # skip head or empty line if it's there\n",
    "            try:\n",
    "                x, y = int(row[1]), int(row[2])\n",
    "                points[row[0]] = (x, y)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e880ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_convex_hull(points):\n",
    "    hull = []\n",
    "    hullIndex = cv2.convexHull(np.array(list(points.values())), clockwise=False, returnPoints=False)\n",
    "    addPoints = [\n",
    "        [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59],  # Outer lips\n",
    "        [60], [61], [62], [63], [64], [65], [66], [67],  # Inner lips\n",
    "        [27], [28], [29], [30], [31], [32], [33], [34], [35],  # Nose\n",
    "        [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47],  # Eyes\n",
    "        [17], [18], [19], [20], [21], [22], [23], [24], [25], [26]  # Eyebrows\n",
    "    ]\n",
    "    hullIndex = np.concatenate((hullIndex, addPoints))\n",
    "    for i in range(0, len(hullIndex)):\n",
    "        hull.append(points[str(hullIndex[i][0])])\n",
    " \n",
    "    return hull, hullIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ddbc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter(filter_name=\"dog\"):\n",
    " \n",
    "    filters = filters_config[filter_name]\n",
    " \n",
    "    multi_filter_runtime = []\n",
    " \n",
    "    for filter in filters:\n",
    "        temp_dict = {}\n",
    " \n",
    "        img1, img1_alpha = load_filter.img(filter['path'], filter['has_alpha'])\n",
    " \n",
    "        temp_dict['img'] = img1\n",
    "        temp_dict['img_a'] = img1_alpha\n",
    " \n",
    "        points = load_landmarks(filter['anno_path'])\n",
    " \n",
    "        temp_dict['points'] = points\n",
    " \n",
    "        if filter['morph']:\n",
    "            # Find convex hull for delaunay triangulation using the landmark points\n",
    "            hull, hullIndex = find_convex_hull(points)\n",
    " \n",
    "            # Find Delaunay triangulation for convex hull points\n",
    "            sizeImg1 = img1.shape\n",
    "            rect = (0, 0, sizeImg1[1], sizeImg1[0])\n",
    "            dt = fbc.calculateDelaunayTriangles(rect, hull)\n",
    " \n",
    "            temp_dict['hull'] = hull\n",
    "            temp_dict['hullIndex'] = hullIndex\n",
    "            temp_dict['dt'] = dt\n",
    " \n",
    "            if len(dt) == 0:\n",
    "                continue\n",
    " \n",
    "        if filter['animated']:\n",
    "            filter_cap = cv2.VideoCapture(filter['path'])\n",
    "            temp_dict['cap'] = filter_cap\n",
    " \n",
    "        multi_filter_runtime.append(temp_dict)\n",
    " \n",
    "    return filters, multi_filter_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cf2f809",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28840\\2007621784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Load an initial filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0miter_filter_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_filter_runtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_filter_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28840\\1478707387.py\u001b[0m in \u001b[0;36mload_filter\u001b[1;34m(filter_name)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtemp_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg1_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_filter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtemp_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'img'"
     ]
    }
   ],
   "source": [
    "# Process input from webcam or video file\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# Some variables we will need later\n",
    "count = 0\n",
    "isFirstFrame = True\n",
    "sigma = 50\n",
    " \n",
    "# Load an initial filter\n",
    "iter_filter_keys = iter(filters_config.keys())\n",
    "filters, multi_filter_runtime = load_filter(next(iter_filter_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571720d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
